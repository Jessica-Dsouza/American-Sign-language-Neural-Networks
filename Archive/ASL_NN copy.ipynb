{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries and packages\n",
    "# Importing the VGG16 model from Keras\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "\n",
    "# Importing the ResNet50 model from TensorFlow\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 \n",
    "\n",
    "# Importing the Model class from Keras\n",
    "from keras.models import Model                 \n",
    "\n",
    "# Importing the image preprocessing module from Keras\n",
    "from keras.preprocessing import image          \n",
    "\n",
    "# Importing the necessary layers from TensorFlow Keras\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout \n",
    "\n",
    "# Importing NumPy for numerical operations\n",
    "import numpy as np                             \n",
    "\n",
    "# Importing TensorFlow\n",
    "import tensorflow as tf                        \n",
    "\n",
    "# Importing Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt                \n",
    "\n",
    "# Configuring Matplotlib for inline plotting\n",
    "%matplotlib inline                              \n",
    "\n",
    "# Importing the os module for file operations\n",
    "import os                                      \n",
    "\n",
    " # Importing OpenCV for image processing\n",
    "import cv2                                    \n",
    "\n",
    "# Setting the directory path for training data\n",
    "train_dir = \"./training_set\"\n",
    "\n",
    "# Setting the directory path for test data\n",
    "eval_dir = \"./test_set\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to load images from given directories\n",
    "import keras\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for idx, label in enumerate(uniq_labels):\n",
    "        \n",
    "        for file in os.listdir(directory + \"/\" + label):\n",
    "            filepath = directory + \"/\" + label + \"/\" + file\n",
    "            image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
    "            images.append(image)\n",
    "            labels.append(idx)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return(images, labels)\n",
    "\n",
    "uniq_labels = sorted(os.listdir(train_dir))\n",
    "uniq_labels.remove('.DS_Store')\n",
    "\n",
    "images, labels = load_images(directory = train_dir)\n",
    "\n",
    "uniq_labels_eval=sorted(os.listdir(eval_dir))\n",
    "uniq_labels_eval.remove('.DS_Store')\n",
    "\n",
    "if uniq_labels == uniq_labels_eval :\n",
    "    X_eval, y_eval = load_images(directory = eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, stratify = labels)\n",
    "\n",
    "n = len(uniq_labels)\n",
    "train_n = len(X_train)\n",
    "test_n = len(X_test)\n",
    "\n",
    "print(\"Total number of symbols: \", n)\n",
    "print(\"Number of training images: \" , train_n)\n",
    "print(\"Number of testing images: \", test_n)\n",
    "\n",
    "eval_n = len(X_eval)\n",
    "print(\"Number of evaluation images: \", eval_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "y_eval = keras.utils.to_categorical(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0\n",
    "X_eval = X_eval.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising vgg16 \n",
    "classifier_vgg16 = VGG16(input_shape= (64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising resnet50 \n",
    "classifier_resnet = ResNet50(input_shape=(64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't train existing weights for vgg16\n",
    "for layer in classifier_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#don't train existing weights for resnet50\n",
    "for layer in classifier_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16\n",
    "classifier1 = classifier_vgg16.output#head mode\n",
    "classifier1 = Flatten()(classifier1)#adding layer of flatten\n",
    "classifier1 = Dense(units=256, activation='relu')(classifier1)\n",
    "classifier1 = Dropout(0.6)(classifier1)\n",
    "classifier1 = Dense(units=39, activation='softmax')(classifier1)\n",
    "\n",
    "model = Model(inputs = classifier_vgg16.input , outputs = classifier1)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#summary of vgg16\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "#it will take some time to train\n",
    "#vgg16\n",
    "history = model.fit(X_train, y_train, epochs =1, batch_size =5,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model of vgg16\n",
    "model.save('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50\n",
    "classifier2 = classifier_resnet.output#head mode\n",
    "classifier2 = Flatten()(classifier2)#adding layer of flatten\n",
    "classifier2 = Dropout(0.6)(classifier2)\n",
    "classifier2 = Dense(units=39, activation='softmax')(classifier2)\n",
    "\n",
    "model2 = Model(inputs = classifier_resnet.input , outputs = classifier2)\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#summary of resnet50\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "#resnet50\n",
    "history2 = model2.fit(X_train, y_train, epochs =1, batch_size = 5,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving the model of resnet\n",
    "model2.save('model_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')\n",
    "\n",
    "score = model2.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model2.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16\n",
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy of vgg16')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50\n",
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy of resnet50')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_VGG = load_model('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.utils as image\n",
    "\n",
    "#class_names=['1','10','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','Best of luck','I love you','space']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(img):\n",
    "  res=[]\n",
    "  #print(img.shape)\n",
    "  img_4d=img.reshape(-1,64,64,3)\n",
    "  result = model_VGG.predict(img_4d)\n",
    "\n",
    "  for i,j in enumerate(range(result.shape[1])):\n",
    "        #print(result[0][i],j,)\n",
    "        \n",
    "    if result[0][i]==1.0:\n",
    "      res=uniq_labels[j]\n",
    "      print(res)\n",
    "  return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = gr.inputs.Image(shape=(64,64))\n",
    "label = gr.outputs.Label(num_top_classes=5)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
