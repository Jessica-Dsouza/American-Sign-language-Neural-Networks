{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries and packages\n",
    "# Importing the VGG16 model from Keras\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "\n",
    "# Importing the ResNet50 model from TensorFlow\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 \n",
    "\n",
    "# Importing the Model class from Keras\n",
    "from keras.models import Model                 \n",
    "\n",
    "# Importing the image preprocessing module from Keras\n",
    "from keras.preprocessing import image          \n",
    "\n",
    "# Importing the necessary layers from TensorFlow Keras\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout \n",
    "\n",
    "# Importing NumPy for numerical operations\n",
    "import numpy as np                             \n",
    "\n",
    "# Importing TensorFlow\n",
    "import tensorflow as tf                        \n",
    "\n",
    "# Importing Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt                \n",
    "\n",
    "# Configuring Matplotlib for inline plotting\n",
    "%matplotlib inline                              \n",
    "\n",
    "# Importing the os module for file operations\n",
    "import os                                      \n",
    "\n",
    " # Importing OpenCV for image processing\n",
    "import cv2                                    \n",
    "\n",
    "# Setting the directory path for training data\n",
    "train_dir = \"./training_set\"\n",
    "\n",
    "# Setting the directory path for test data\n",
    "eval_dir = \"./test_set\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a helper function to load images from given directories\n",
    "import keras  # Importing Keras\n",
    "\n",
    "def load_images(directory):\n",
    "    images = []    # Initializing an empty list to store images\n",
    "    labels = []    # Initializing an empty list to store labels\n",
    "    for idx, label in enumerate(uniq_labels):   # Iterating through the list of unique labels\n",
    "\n",
    "        for file in os.listdir(directory + \"/\" + label):   # Iterating through the files in the given directory and label\n",
    "            \n",
    "            filepath = directory + \"/\" + label + \"/\" + file    # Getting the file path\n",
    "            image = cv2.resize(cv2.imread(filepath), (64, 64))   # Reading and resizing the image using OpenCV\n",
    "            images.append(image)    # Appending the image to the list of images\n",
    "            labels.append(idx)      # Appending the label index to the list of labels\n",
    "    images = np.array(images)      # Converting the list of images to a NumPy array\n",
    "    labels = np.array(labels)      # Converting the list of labels to a NumPy array\n",
    "    return(images, labels)         # Returning the images and labels as NumPy arrays\n",
    "\n",
    "# Getting the list of unique labels from the training directory\n",
    "uniq_labels = sorted(os.listdir(train_dir))\n",
    "uniq_labels.remove('.DS_Store')   # Removing the .DS_Store file from the list of labels if present\n",
    "\n",
    "# Loading the images and labels from the training directory\n",
    "images, labels = load_images(directory = train_dir)\n",
    "\n",
    "# Getting the list of unique labels from the evaluation directory\n",
    "uniq_labels_eval=sorted(os.listdir(eval_dir))\n",
    "uniq_labels_eval.remove('.DS_Store')   # Removing the .DS_Store file from the list of labels if present\n",
    "\n",
    "# Checking if the list of unique labels from the training and evaluation directory are the same\n",
    "if uniq_labels == uniq_labels_eval :\n",
    "    # Loading the images and labels from the evaluation directory if the labels are the same\n",
    "    X_eval, y_eval = load_images(directory = eval_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the images and labels into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, stratify = labels)\n",
    "\n",
    "# Getting the number of unique labels, training images, and testing images\n",
    "n = len(uniq_labels)\n",
    "train_n = len(X_train)\n",
    "test_n = len(X_test)\n",
    "\n",
    "# Printing the total number of unique symbols, number of training images, and number of testing images\n",
    "print(\"Total number of symbols: \", n)\n",
    "print(\"Number of training images: \" , train_n)\n",
    "print(\"Number of testing images: \", test_n)\n",
    "\n",
    "# Getting the number of evaluation images\n",
    "eval_n = len(X_eval)\n",
    "\n",
    "# Printing the number of evaluation images\n",
    "print(\"Number of evaluation images: \", eval_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels to categorical arrays for training, testing, and evaluation datasets\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "y_eval = keras.utils.to_categorical(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the categorical label of the first image in the training set\n",
    "print(y_train[0])\n",
    "\n",
    "# Printing the length of the categorical label\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the pixel values of the images to float and scaling them between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_eval = X_eval.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing VGG16 and ResNet50 models with ImageNet weights and without the top layer\n",
    "# The input shape is (64, 64, 3) as our images are resized to 64x64 pixels and have 3 color channels (RGB)\n",
    "classifier_vgg16 = VGG16(input_shape=(64, 64, 3), include_top=False, weights='imagenet')\n",
    "classifier_resnet = ResNet50(input_shape=(64, 64, 3), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the layers of the pre-trained models as non-trainable\n",
    "# We don't want to update the weights of the pre-trained models during training\n",
    "for layer in classifier_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in classifier_resnet.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16\n",
    "# Getting the output of the VGG16 convolutional base as input for the new model\n",
    "classifier1 = classifier_vgg16.output\n",
    "\n",
    "# Adding a flatten layer to convert the output into a 1D feature vector\n",
    "classifier1 = Flatten()(classifier1)\n",
    "\n",
    "# Adding a fully connected dense layer with 256 units and ReLU activation\n",
    "classifier1 = Dense(units=256, activation='relu')(classifier1)\n",
    "\n",
    "# Adding a dropout layer to prevent overfitting\n",
    "classifier1 = Dropout(0.6)(classifier1)\n",
    "\n",
    "# Adding the output layer with softmax activation and 39 units (number of classes)\n",
    "classifier1 = Dense(units=39, activation='softmax')(classifier1)\n",
    "\n",
    "# Creating the final model using the VGG16 convolutional base as input and the new classifier as output\n",
    "model = Model(inputs = classifier_vgg16.input , outputs = classifier1)\n",
    "\n",
    "# Compiling the model with Adam optimizer, categorical crossentropy loss and accuracy metrics\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Printing the summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on training data and evaluate on testing data for 5 epochs \n",
    "history = model.fit(X_train, y_train, epochs =5, batch_size =32,validation_data=(X_test,y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the head model for resnet50\n",
    "classifier2 = classifier_resnet.output\n",
    "classifier2 = Flatten()(classifier2) # Adding a layer of flatten\n",
    "classifier2 = Dropout(0.6)(classifier2)\n",
    "classifier2 = Dense(units=39, activation='softmax')(classifier2)\n",
    "\n",
    "# Initializing the model with resnet50 as the base\n",
    "model2 = Model(inputs=classifier_resnet.input, outputs=classifier2)\n",
    "\n",
    "# Compiling the model\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Printing the summary of the model\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ResNet50 model\n",
    "history2 = model2.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained ResNet50 model\n",
    "model2.save('model_resnet.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating accuracy on the test images for VGG16 model\n",
    "score = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "\n",
    "# Evaluating accuracy on the evaluation images for VGG16 model\n",
    "score = model.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')\n",
    "\n",
    "# Evaluating accuracy on the test images for ResNet50 model\n",
    "score = model2.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "\n",
    "# Evaluating accuracy on the evaluation images for ResNet50 model\n",
    "score = model2.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing accuracy and loss for VGG16 model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy for VGG16')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss for VGG16')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50\n",
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the training accuracy and validation accuracy for resnet50 model\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy of resnet50')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot the training loss and validation loss for resnet50 model\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_VGG = load_model('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.utils as image\n",
    "\n",
    "#class_names=['1','10','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','Best of luck','I love you','space']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(img):\n",
    "  res=[]\n",
    "  #print(img.shape)\n",
    "  img_4d=img.reshape(-1,64,64,3)\n",
    "  result = model_VGG.predict(img_4d)\n",
    "\n",
    "  for i,j in enumerate(range(result.shape[1])):\n",
    "        #print(result[0][i],j,)\n",
    "        \n",
    "    if result[0][i]==1.0:\n",
    "      res=uniq_labels[j]\n",
    "      print(res)\n",
    "  return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = gr.inputs.Image(shape=(64,64))\n",
    "label = gr.outputs.Label(num_top_classes=5)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for only one prediction\n",
    "import numpy as np\n",
    "import keras.utils as image\n",
    "for i in uniq_labels:\n",
    "    test_image = image.load_img(f'test_set/{i}/100.png',target_size=(64,64))\n",
    "    #plt.imshow(test_image)\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = model.predict(test_image)\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    # if result[0][0] == 1:             \n",
    "    #     prediction = '1'\n",
    "    # elif result[0][1] == 1:\n",
    "    #     prediction = '10'\n",
    "    # elif result[0][2] == 1:\n",
    "    #     prediction = '2'\n",
    "    # elif result[0][3] == 1:\n",
    "    #     prediction = '3'\n",
    "    # elif result[0][4] == 1:\n",
    "    #     prediction = '4'\n",
    "    # elif result[0][5] == 1:\n",
    "    #     prediction = '5'\n",
    "    # elif result[0][6] == 1:\n",
    "    #     prediction = '6'\n",
    "    # elif result[0][7] == 1:\n",
    "    #     prediction = '7'\n",
    "    # elif result[0][8] == 1:\n",
    "    #     prediction = '8'\n",
    "    # elif result[0][9] == 1:\n",
    "    #     prediction = '9'\n",
    "    # elif result[0][10] == 1:\n",
    "    #     prediction = 'A'\n",
    "    # elif result[0][11] == 1:\n",
    "    #     prediction = 'B'\n",
    "    # elif result[0][12] == 1:\n",
    "    #     prediction = 'C'\n",
    "    # elif result[0][13] == 1:\n",
    "    #     prediction = 'D'\n",
    "    # elif result[0][14] == 1:\n",
    "    #     prediction = 'E'\n",
    "    # elif result[0][15] == 1:\n",
    "    #     prediction = 'F'\n",
    "    # elif result[0][16] == 1:\n",
    "    #     prediction = 'G'\n",
    "    # elif result[0][17] == 1:\n",
    "    #     prediction = 'H'\n",
    "    # elif result[0][18] == 1:\n",
    "    #     prediction = 'I'\n",
    "    # elif result[0][19] == 1:\n",
    "    #     prediction = 'J'\n",
    "    # elif result[0][20] == 1:\n",
    "    #     prediction = 'K'\n",
    "    # elif result[0][21] == 1:\n",
    "    #     prediction = 'L'\n",
    "    # elif result[0][22] == 1:\n",
    "    #     prediction = 'M'\n",
    "    # elif result[0][23] == 1:\n",
    "    #     prediction = 'N'\n",
    "    # elif result[0][24] == 1:\n",
    "    #     prediction = 'O'\n",
    "    # elif result[0][25] == 1:\n",
    "    #     prediction = 'P'\n",
    "    # elif result[0][26] == 1:\n",
    "    #     prediction = 'Q'\n",
    "    # elif result[0][27] == 1:\n",
    "    #     prediction = 'R'\n",
    "    # elif result[0][28] == 1:\n",
    "    #     prediction = 'S'\n",
    "    # elif result[0][29] == 1:\n",
    "    #     prediction = 'T'\n",
    "    # elif result[0][30] == 1:\n",
    "    #     prediction = '1'\n",
    "    # elif result[0][31] == 1:\n",
    "    #     prediction = 'V'\n",
    "    # elif result[0][32] == 1:\n",
    "    #     prediction = 'W'\n",
    "    # elif result[0][33] == 1:\n",
    "    #     prediction = 'X'\n",
    "    # elif result[0][34] == 1:\n",
    "    #     prediction = 'Y'\n",
    "    # elif result[0][35] == 1:\n",
    "    #     prediction = 'Z'\n",
    "    # elif result[0][36] == 1:\n",
    "    #     prediction = 'best of luck'\n",
    "    # elif result[0][37] == 1:\n",
    "    #     prediction = 'i love you'\n",
    "    # elif result[0][38] == 1:\n",
    "    #     prediction = 'space'\n",
    "    # else:\n",
    "    #     prediction = 'INVALID'\n",
    "        \n",
    "    # print(\"what it should be : \",i)\n",
    "    # print(\"what it is:\",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
